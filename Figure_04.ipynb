{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zhang Chao, 2025/04/03<br>\n",
    "Contribution of environmental factors to the cooling trends<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import statsmodels.api as sm\n",
    "import regionmask\n",
    "from scipy.stats import linregress\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/climate/chaoz/code/utils/')\n",
    "from plot_utils import plot_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/climate/chaoz/project/03Irr_Ts_CN/processed/')\n",
    "BGC = xr.open_dataset('bgc_terraclimate_Yr_CN_1km_2001_2020.nc')\n",
    "dLSTd = xr.open_dataset('delta_LSTday_Yr_CN_2001_2020.nc')\n",
    "dLSTn = xr.open_dataset('delta_LSTnight_Yr_CN_2001_2020.nc')\n",
    "dEVI  = xr.open_dataset('delta_EVI_Yr_CN_2001_2020.nc')\n",
    "\n",
    "shp_cn = gpd.read_file('../shapefile/ChinaAll.shp')\n",
    "shp_nanhai = gpd.read_file('../shapefile/Nanhai.shp')\n",
    "shp_climzone = gpd.read_file('../shapefile/ClimateZone_3.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_regionmean(ds,varname,shp):\n",
    "    \"\"\"Calculate the national and regional mean values\n",
    "\n",
    "    Args:\n",
    "        ds (xarray dataset): time-series dataset\n",
    "        varname (str): the variable name in the xarray dataset\n",
    "        shp (geo dataframe): shapefile loaded by geopandas.read_file()\n",
    "\n",
    "    Returns:\n",
    "        numpy.dataframe: time-series annual means for different regions\n",
    "    \"\"\"\n",
    "    # Calculate the national mean values\n",
    "    stat_cn = ds.mean(dim=('lat','lon'))[varname].values\n",
    "    \n",
    "    mask_region = regionmask.mask_geopandas(shp,ds.lon,ds.lat)\n",
    "    stat_region = ds.groupby(mask_region).mean().to_dataframe().reset_index()\n",
    "    \n",
    "    mask_mapping = {0.0:'Humid', 1.0:'Arid', 2.0:'Semi'}\n",
    "    stat_region['mask'] = stat_region['mask'].replace(mask_mapping)\n",
    "    \n",
    "    # Rearrange the dataframe by the different masks (regions)\n",
    "    pivoted_df = stat_region.pivot_table(index='time', columns='mask', values=varname).reset_index()\n",
    "    # Append the national mean values as a column 'China'\n",
    "    pivoted_df['China'] = stat_cn\n",
    "    \n",
    "    # Re-order the columns\n",
    "    pivoted_df = pivoted_df[['time','China','Arid','Semi','Humid']]\n",
    "    \n",
    "    return pivoted_df\n",
    "\n",
    "\n",
    "def get_contribution(dlst,iwu,pr,ta,sr,ws,devi,region):\n",
    "    df = pd.DataFrame({\n",
    "                     'dLst':dlst[region][2:].to_list(),\n",
    "                     'dIwu':iwu[region].to_list(),\n",
    "                     'Pr':pr[region][2:].to_list(),\n",
    "                     'Ta':ta[region][2:].to_list(),\n",
    "                     'Sr':sr[region][2:].to_list(),\n",
    "                     'Ws':ws[region][2:].to_list(),\n",
    "                     'dEvi':devi[region][2:].to_list(),\n",
    "                     })\n",
    "\n",
    "    slopes = {col: linregress(range(len(df[col])), df[col]).slope for col in df.columns}\n",
    "    \n",
    "    vars_y = ['dLst']\n",
    "    vars_x = ['dIwu','Pr','Ta','Sr','Ws','dEvi']\n",
    "    \n",
    "    x = sm.add_constant(df[vars_x])\n",
    "    y = df[vars_y]\n",
    "    model = sm.OLS(y, x)\n",
    "    result = model.fit()\n",
    "    result.params\n",
    "    \n",
    "    out_r = {'pval' : result.f_pvalue ,\n",
    "    'r2'    :result.rsquared,\n",
    "    'tr'    : slopes['dLst'],\n",
    "    'tr2iwu': result.params.iloc[1] * slopes['dIwu'],\n",
    "    'tr2evi': result.params.iloc[6] * slopes['dEvi'],\n",
    "    'tr2bc' : result.params.iloc[2] * slopes['Pr']  \n",
    "            + result.params.iloc[3] * slopes['Ta']  \n",
    "            + result.params.iloc[4] * slopes['Sr']  \n",
    "            + result.params.iloc[5] * slopes['Ws']    \n",
    "    }\n",
    "    \n",
    "    return out_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe regional statistics are written to csv files, loading them\\nagain because the calculation process is time-intensive.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The regional statistics are written to csv files, loading them\n",
    "again because the calculation process is time-intensive.\n",
    "'''\n",
    "# df_pr = stats_regionmean(BGC,'pr',shp_climzone)\n",
    "# df_ta = stats_regionmean(BGC,'ta',shp_climzone)\n",
    "# df_sr = stats_regionmean(BGC,'sr',shp_climzone)\n",
    "# df_ws = stats_regionmean(BGC,'ws',shp_climzone)\n",
    "# df_dEVI = stats_regionmean(dEVI,'EVI',shp_climzone)\n",
    "# df_pr.to_csv('regionmean_pr.csv')\n",
    "# df_sr.to_csv('regionmean_sr.csv')\n",
    "# df_ta.to_csv('regionmean_ta.csv')\n",
    "# df_ws.to_csv('regionmean_ws.csv')\n",
    "# df_dEVI.to_csv('regionmean_dEVI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dLSTday   = pd.read_csv('regionmean_dLSTday_Yr.csv')\n",
    "df_dLSTnight = pd.read_csv('regionmean_dLSTnight_Yr.csv')\n",
    "df_IWU       = pd.read_csv('regionmean_IWU_Yr.csv')\n",
    "df_pr        = pd.read_csv('regionmean_pr.csv')\n",
    "df_sr        = pd.read_csv('regionmean_sr.csv')\n",
    "df_ta        = pd.read_csv('regionmean_ta.csv')\n",
    "df_ws        = pd.read_csv('regionmean_ws.csv')\n",
    "df_dEVI      = pd.read_csv('regionmean_dEVI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get the regional trend contributed by iwu, background climate, and evi\n",
    "'''\n",
    "regions=['China','Arid','Semi','Humid']\n",
    "con_day = [get_contribution(df_dLSTday,df_IWU,df_pr,df_ta,df_sr,df_ws,df_dEVI,region) for region in regions]\n",
    "df_con_day = pd.DataFrame(con_day)\n",
    "df_con_day.index = regions\n",
    "df_con_day = df_con_day.T\n",
    "\n",
    "con_night = [get_contribution(df_dLSTnight,df_IWU,df_pr,df_ta,df_sr,df_ws,df_dEVI,region) for region in regions]\n",
    "df_con_night = pd.DataFrame(con_night)\n",
    "df_con_night.index = regions\n",
    "\n",
    "df_con_night = df_con_night.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1,p2=0.01,0.05\n",
    "yticks = ['OBS','IWU','CGN', 'BGC']#,'Res'\n",
    "# yticks = ['Observation','WSI', 'Crop greening','Background climate']#,'Res'\n",
    "\n",
    "'''significance level'''\n",
    "def getSigFlag(p):\n",
    "    strSig = ''\n",
    "    if p<p1:\n",
    "        strSig = '**'\n",
    "    elif p<p2:\n",
    "        strSig = '*'\n",
    "    else:\n",
    "        strSig = ''\n",
    "    return strSig\n",
    "\n",
    "\n",
    "def DrawGraph(fig,pos,df,No,ylabelflag,xlabelflag,ylabel):\n",
    "    ax = fig.add_axes(pos)\n",
    "    pval = df.iloc[0]\n",
    "    r2   = df.iloc[1]\n",
    "    newdfc = df[2:] * 10\n",
    "    \n",
    "    yax = [4,3,2,1]\n",
    "    ax.barh(y = yax,width=newdfc,height=0.8,color=colors)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_xlim([-0.12,0.12])\n",
    "\n",
    "    ax.text(-0.11,1.02,No,weight='bold',fontsize=14,transform = ax.transAxes)\n",
    "    if ylabelflag == True:\n",
    "        ax.set_yticks(yax,yticks)\n",
    "        ax.set_ylabel(ylabel)\n",
    "    else:\n",
    "        ax.set_yticks(yax,['','','',''])\n",
    "    if xlabelflag == True:\n",
    "        ax.set_xlabel('$\\Delta$LST trend [K/decade]',y=-0.1)\n",
    "    ax.text(0.25, 1.05, 'R$^2$ = %.2f%s'%(r2,getSigFlag(pval))\n",
    "             , transform=ax.transAxes)\n",
    "    ax.axvline(x=0.0, c=\"k\", alpha=0.4, ls=\"--\", lw=1)\n",
    "\n",
    "\n",
    "def DrawGraph_com(fig,pos,df,No,ylabelflag,xlabelflag,ylabel):\n",
    "    # Define positions for the two sub-axes\n",
    "    pos1 = [pos[0], pos[1], pos[2]*6/7, pos[3]]  # Upper part\n",
    "    pos2 = [pos[0]+pos[2]*6/7+0.007, pos[1], pos[2]*1/7, pos[3]]  # Lower part\n",
    "    pos3 = [pos[0]+0.10,pos[1],0.10,0.18]\n",
    "    # Create two axes for the broken y-axis\n",
    "    ax1, ax2 = fig.add_axes(pos1), fig.add_axes(pos2)\n",
    "    ax3 = fig.add_axes(pos3)\n",
    "    ax3.patch.set_alpha(0)\n",
    "\n",
    "    pval = df.iloc[0]\n",
    "    r2   = df.iloc[1]\n",
    "    newdfc = df[2:] * 10\n",
    "    \n",
    "    yax = [4,3,2,1]\n",
    "    ax1.barh(y = yax,width=newdfc,height=0.7,color=colors)\n",
    "    ax2.barh(y = yax,width=newdfc,height=0.7,color=colors)\n",
    "\n",
    "    ax1.axvline(x=0.0, c=\"k\", alpha=0.4, ls=\"--\", lw=1)\n",
    "    # **Set Y-axis limits based on breaks**\n",
    "    ax1.set_xlim([-0.12,0.12])  # Upper part\n",
    "    ax2.set_xlim([0.19, 0.23])  # Lower part\n",
    "    \n",
    "    if ylabelflag == True:\n",
    "        ax1.set_yticks(yax,yticks)\n",
    "        ax1.set_ylabel(ylabel,labelpad=10)\n",
    "    else:\n",
    "        ax1.set_yticks(yax,['','','',''])\n",
    "    \n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xticks([0.20],['0.20'])\n",
    "    \n",
    "    # Add diagonal break marks\n",
    "    d = .01  # size of diagonal lines\n",
    "    kwargs = dict(transform=ax1.transAxes, color='k', clip_on=False, linewidth=1)\n",
    "    ax1.plot((1 - d, 1 + d), (-d, +d), **kwargs)  # top-right\n",
    "\n",
    "    kwargs.update(transform=ax2.transAxes)\n",
    "    ax2.plot((-10*d, +d), (-d, +d), **kwargs)  # top-left\n",
    "    \n",
    "    ax1.set_xticks([-0.05,0,0.05],[-0.05,0,0.05])\n",
    "    ax1.text(-0.11,1.02,No,weight='bold',fontsize=14,transform = ax1.transAxes)\n",
    "    \n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.spines['left'].set_visible(False)\n",
    "    \n",
    "    for spine in ax3.spines.values():\n",
    "        spine.set_visible(True)\n",
    "\n",
    "    def autopct_func(pct):\n",
    "        return f'{pct:.0f}' if pct > 6 else ''\n",
    "    \n",
    "    total = abs(newdfc.iloc[1]) + abs(newdfc.iloc[2]) + abs(newdfc.iloc[3])\n",
    "    newdfc2 = [abs(newdfc.iloc[1])/total,abs(newdfc.iloc[2])/total,abs(newdfc.iloc[3])/total]\n",
    "    wedges, texts , autotexts= ax3.pie(newdfc2, colors=colors[1:], radius=1.0, startangle=90,\n",
    "                        wedgeprops=dict(width=0.6, edgecolor='w'),\n",
    "                        autopct=autopct_func,pctdistance=0.73)#'%1.0f'\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('w')\n",
    "        \n",
    "    ax3.text(0.44, 0.45,'%', transform=ax3.transAxes)\n",
    "    return ax1 # Return the two axes\n",
    "\n",
    "\n",
    "colors = ['gray','#1E88E5','#33A02C','#FFA726']\n",
    "\n",
    "fig = plt.figure(figsize=(9,5))\n",
    "plot_settings()\n",
    "\n",
    "x0,y0 = 0.08,0.09\n",
    "xi,yi = 0.04,0.15\n",
    "hx1,vx1 = (1-x0-3*xi-0.01)/4,0.35\n",
    "\n",
    "pos11 = [x0+(hx1+xi)*0, y0+(vx1+yi)*1, hx1, vx1]\n",
    "pos12 = [x0+(hx1+xi)*1, y0+(vx1+yi)*1, hx1, vx1]\n",
    "pos13 = [x0+(hx1+xi)*2, y0+(vx1+yi)*1, hx1, vx1]\n",
    "pos14 = [x0+(hx1+xi)*3, y0+(vx1+yi)*1, hx1, vx1]\n",
    "\n",
    "pos21 = [x0+(hx1+xi)*0, y0+(vx1+yi)*0, hx1, vx1]\n",
    "pos22 = [x0+(hx1+xi)*1, y0+(vx1+yi)*0, hx1, vx1]\n",
    "pos23 = [x0+(hx1+xi)*2, y0+(vx1+yi)*0, hx1, vx1]\n",
    "pos24 = [x0+(hx1+xi)*3, y0+(vx1+yi)*0, hx1, vx1]\n",
    "\n",
    "\n",
    "ax11 = DrawGraph_com(fig, pos11,df_con_day['China']  ,'a',True , False, 'Day')\n",
    "ax12 = DrawGraph_com(fig, pos12,df_con_day['Arid']   ,'b',False, False, '')\n",
    "ax13 = DrawGraph_com(fig, pos13,df_con_day['Semi']   ,'c',False, False, '')\n",
    "ax14 = DrawGraph_com(fig, pos14,df_con_day['Humid']  ,'d',False, False, '')\n",
    "ax21 = DrawGraph_com(fig, pos21,df_con_night['China'],'e',True , False, 'Night')\n",
    "ax22 = DrawGraph_com(fig, pos22,df_con_night['Arid'] ,'f',False, False, '')\n",
    "ax23 = DrawGraph_com(fig, pos23,df_con_night['Semi'] ,'g',False, False, '')\n",
    "ax24 = DrawGraph_com(fig, pos24,df_con_night['Humid'],'h',False, False, '')\n",
    "\n",
    "ax11.set_title('China')\n",
    "ax12.set_title('Arid')\n",
    "ax13.set_title('Semi-arid/humid',loc='right')\n",
    "ax14.set_title('Humid')\n",
    "\n",
    "ax21.set_xlabel('Trend [K/decade]',loc='right')\n",
    "ax22.set_xlabel('Trend [K/decade]',loc='right')\n",
    "ax23.set_xlabel('Trend [K/decade]',loc='right')\n",
    "ax24.set_xlabel('Trend [K/decade]',loc='right')\n",
    "\n",
    "plt.savefig('../figures/Figure_04.png',dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
